{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read IEX_TOKEN and IEX_API_VERSION from .env file\n",
    "\n",
    "import os\n",
    "\n",
    "with open('.env', 'r') as env:\n",
    "    os.environ.update({line.split('=')[0].strip(): line.split('=')[1].strip() for line in  filter(lambda li: '=' in li, env.read().split('\\n'))})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value: 5055.96, return: 1.5451071606579163%\n"
     ]
    }
   ],
   "source": [
    "import iexfinance\n",
    "import pandas as pd\n",
    "\n",
    "# Setup cache for requests\n",
    "import datetime\n",
    "from iexfinance.stocks import Stock\n",
    "import requests_cache\n",
    "\n",
    "expiry = datetime.timedelta(days=100)\n",
    "session = requests_cache.CachedSession(cache_name='cache',\n",
    "                                       backend='sqlite',\n",
    "                                       expire_after=expiry)\n",
    "\n",
    "vuke = Stock('VUKE-LN')\n",
    "\n",
    "\"\"\"\n",
    "purchased on \n",
    "Order summary\n",
    "Estimated value more information £5,000.00 \n",
    "Order number 5674775\n",
    "Status updated\n",
    "Date 03 March 2021\n",
    "Time 10:16\n",
    "Actual contract cost\n",
    "Value £4,977.62\n",
    "Settlement price £29.63\n",
    "Contract total £4,977.62\n",
    "\"\"\"\n",
    "\n",
    "no_shares = 168.0000\n",
    "buy_price = 29.63\n",
    "\n",
    "price = vuke.get_price()\n",
    "price = price['VUKE-LN'].values[0]\n",
    "\n",
    "value = price * no_shares\n",
    "returns = (price - buy_price)/price\n",
    "print(f'value: {value}, return: {returns*100}%')\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Static data\n",
    "emea_cty_codes = ['AT','BE','BG','HR','CY','CZ','DK','EE','FI','FR','DE','GR','HU','IE','IT','LV','LT','LU','MT','NL','PL','PT','RO','SK','SI','ES','SE','GB']\n",
    "\n",
    "with open('./data/iex_exchanges.json', 'r') as fil:\n",
    "    df = pd.read_json(fil)\n",
    "iex_exchanges = df\n",
    "\n",
    "from iexfinance.refdata import get_region_symbols\n",
    "\n",
    "def download_symbol_static():\n",
    "    df = pd.DataFrame()\n",
    "    for cty_code in emea_cty_codes:\n",
    "        if cty_code in iex_exchanges.region.values:\n",
    "            symbols = get_region_symbols(cty_code)\n",
    "            if len(symbols) == 0:\n",
    "                print(f'cty_code={cty_code} not found')\n",
    "                continue\n",
    "            df = df.append(symbols)\n",
    "        else:\n",
    "            print(f'cty_code={cty_code} is not supported by iex')\n",
    "    all_emea_symbols = df\n",
    "    all_emea_symbols.to_csv('data/all_emea_symbols.csv')\n",
    "    return all_emea_symbols\n",
    "\n",
    "# EMEA Universe\n",
    "all_emea_symbols = pd.read_csv('./data/all_emea_symbols.csv')\n",
    "\n",
    "# FTSE 100 data\n",
    "ftse_companies = pd.read_csv('./data/ftse100.csv')\n",
    "ftse_tickers = list(map(lambda tick: f'{tick}-LN', ftse_companies.Code))\n",
    "\n",
    "# data on vanguard etfs\n",
    "vg_etfs = pd.read_csv('/home/rory/dev/investment-analysis/data/vanguard_fund_summaries.csv')\n",
    "vanguard_funds = all_emea_symbols[all_emea_symbols.name.str.contains('Vanguard')]\n",
    "vanguard_funds.name\n",
    "\n",
    "# Vanguard etf tickers\n",
    "tickers=list(map(lambda it: it.replace(' ', '-'), list(vg_etfs.Bloomberg)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "# Model Features\n",
    "################\n",
    "# VG ETF prices\n",
    "vg_etf_basket = Stock(tickers, session=session)\n",
    "vg_etf_prices = vg_etf_basket.get_historical_prices(range='5y')\n",
    "vg_etf_prices = process_basket_data(vg_etf_prices)\n",
    "\n",
    "# VG Momentum funds\n",
    "momentum_etfs = Stock(list(vanguard_funds[vanguard_funds.symbol.str.contains('VMOM')].symbol.values), session=session)\n",
    "momentum_prices = momentum_etfs.get_historical_prices(range='5y')\n",
    "momentum_prices = process_basket_data(momentum_prices)\n",
    "\n",
    "# FTSE 100 names\n",
    "ftse_basket = Stock(list(ftse_tickers[0:100]), session=session)\n",
    "ftse_basket_prices = ftse_basket.get_historical_prices(range='5y')\n",
    "ftse_basket_prices = process_basket_data(ftse_basket_prices)\n",
    "\n",
    "# Filter out columns with too few observations\n",
    "mask = [tick for tick in filter(lambda ticker: ftse_basket_prices.loc[ticker].close.size >=1200, ftse_basket_prices.index.levels[0])]\n",
    "ftse_basket_prices = ftse_basket_prices.loc[mask]\n",
    "\n",
    "\n",
    "####################\n",
    "# Prediction Targets\n",
    "####################\n",
    "# FTSE100 INDEX\n",
    "ftse100 = Stock('VUKE-LN', session=session)\n",
    "ftse100_prices = ftse100.get_historical_prices(range='5y')\n",
    "ftse100_prices.index = pd.to_datetime(ftse100_prices.index)\n",
    "\n",
    "ftse250 = Stock('VMID-LN', session=session)\n",
    "ftse250_prices = ftse250.get_historical_prices(range='5y')\n",
    "ftse250_prices.index = pd.to_datetime(ftse250_prices.index)\n",
    "ftse250_prices\n",
    "\n",
    "\n",
    "ftse_basket_prices.index.levels[0]\n",
    "\n",
    "ftse_prediction = normalise_basket(ftse_basket_prices, 'returns').dropna()\n",
    "ftse_prediction['index'] = daily_returns(ftse100_prices.close.astype('float'))\n",
    "ftse_prediction['target'] = ftse_prediction['index'].astype('float').apply(lambda ret: 1 if ret > 0 else 0)\n",
    "\n",
    "ftse_prediction = ftse_prediction.dropna()[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2016-03-14    0.004692\n",
       "2016-03-15   -0.005928\n",
       "2016-03-16    0.006325\n",
       "2016-03-17   -0.006285\n",
       "2016-03-18   -0.002530\n",
       "                ...   \n",
       "2021-03-04   -0.000338\n",
       "2021-03-05   -0.004654\n",
       "2021-03-08    0.013347\n",
       "2021-03-09    0.002852\n",
       "2021-03-10   -0.001171\n",
       "Name: index, Length: 1260, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftse_prediction['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "con=sqlite3.connect('./example.db')\n",
    "ftse_prediction.to_sql(name='ftse_prediction', if_exists='replace', con=con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## apply lag to x of 1, so we only ever use yesterday's close price of components\n",
    "period_lag = -1\n",
    "ftse_prediction['target'] = ftse_prediction.target.shift(period_lag)\n",
    "ftse_prediction['index'] = ftse_prediction['index'].shift(period_lag)\n",
    "#ftse_prediction = ftse_prediction[period_lag:]\n",
    "\n",
    "\n",
    "#################\n",
    "# Features Subset\n",
    "#################\n",
    "test_cols = list(filter(lambda it: it not in [ 'index', 'target'] and 'minus' not in it, ftse_prediction.columns))\n",
    "for col in test_cols:\n",
    "    for i in range(1,6):\n",
    "        ftse_prediction[f'{col}_tminus{i}'] = ftse_prediction[col].shift(i)\n",
    "test_cols = list(filter(lambda it: it not in [ 'index', 'target'], ftse_prediction.columns))\n",
    "\n",
    "ftse_prediction.dropna(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "con = sqlite3.connect('example.db')\n",
    "\n",
    "\n",
    "\n",
    "ftse_prediction = pd.read_sql('select * from ftse_prediction', con)\n",
    "test_cols = list(filter(lambda it: it not in [ 'index', 'target'], ftse_prediction.columns))\n",
    "ftse_prediction.index = pd.to_datetime(ftse_prediction['level_0'])\n",
    "ftse_prediction = ftse_prediction[['target', 'index'] + test_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>index</th>\n",
       "      <th>level_0</th>\n",
       "      <th>AAL-LN</th>\n",
       "      <th>ABF-LN</th>\n",
       "      <th>ADM-LN</th>\n",
       "      <th>AHT-LN</th>\n",
       "      <th>ANTO-LN</th>\n",
       "      <th>AUTO-LN</th>\n",
       "      <th>AV.-LN</th>\n",
       "      <th>...</th>\n",
       "      <th>STAN-LN</th>\n",
       "      <th>STJ-LN</th>\n",
       "      <th>SVT-LN</th>\n",
       "      <th>TSCO-LN</th>\n",
       "      <th>TW.-LN</th>\n",
       "      <th>ULVR-LN</th>\n",
       "      <th>UU.-LN</th>\n",
       "      <th>VOD-LN</th>\n",
       "      <th>WPP-LN</th>\n",
       "      <th>WTB-LN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-03-14</th>\n",
       "      <td>1</td>\n",
       "      <td>0.004692</td>\n",
       "      <td>2016-03-14 00:00:00</td>\n",
       "      <td>0.059930</td>\n",
       "      <td>0.004770</td>\n",
       "      <td>-0.020366</td>\n",
       "      <td>0.038217</td>\n",
       "      <td>0.025763</td>\n",
       "      <td>-0.001576</td>\n",
       "      <td>-0.025636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033668</td>\n",
       "      <td>0.010626</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.004943</td>\n",
       "      <td>0.029826</td>\n",
       "      <td>0.004683</td>\n",
       "      <td>0.007804</td>\n",
       "      <td>0.010352</td>\n",
       "      <td>0.006390</td>\n",
       "      <td>0.035554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-15</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.005928</td>\n",
       "      <td>2016-03-15 00:00:00</td>\n",
       "      <td>-0.108051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006397</td>\n",
       "      <td>0.001227</td>\n",
       "      <td>-0.044651</td>\n",
       "      <td>-0.001842</td>\n",
       "      <td>-0.013466</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040430</td>\n",
       "      <td>-0.003874</td>\n",
       "      <td>0.006783</td>\n",
       "      <td>-0.015015</td>\n",
       "      <td>-0.008743</td>\n",
       "      <td>0.010609</td>\n",
       "      <td>-0.004978</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>0.011429</td>\n",
       "      <td>-0.023398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-16</th>\n",
       "      <td>1</td>\n",
       "      <td>0.006325</td>\n",
       "      <td>2016-03-16 00:00:00</td>\n",
       "      <td>0.010770</td>\n",
       "      <td>0.005045</td>\n",
       "      <td>0.006356</td>\n",
       "      <td>0.023284</td>\n",
       "      <td>-0.033301</td>\n",
       "      <td>0.011337</td>\n",
       "      <td>0.014070</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016595</td>\n",
       "      <td>0.038333</td>\n",
       "      <td>0.011550</td>\n",
       "      <td>0.002103</td>\n",
       "      <td>0.034179</td>\n",
       "      <td>-0.006044</td>\n",
       "      <td>0.002223</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>0.002511</td>\n",
       "      <td>-0.008854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-17</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.006285</td>\n",
       "      <td>2016-03-17 00:00:00</td>\n",
       "      <td>0.097828</td>\n",
       "      <td>-0.002657</td>\n",
       "      <td>0.007895</td>\n",
       "      <td>0.023952</td>\n",
       "      <td>0.082796</td>\n",
       "      <td>-0.019812</td>\n",
       "      <td>0.003106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006027</td>\n",
       "      <td>-0.006421</td>\n",
       "      <td>0.014748</td>\n",
       "      <td>0.012064</td>\n",
       "      <td>0.004797</td>\n",
       "      <td>-0.004641</td>\n",
       "      <td>0.008874</td>\n",
       "      <td>-0.002497</td>\n",
       "      <td>-0.003757</td>\n",
       "      <td>0.002102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-18</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.002530</td>\n",
       "      <td>2016-03-18 00:00:00</td>\n",
       "      <td>0.026807</td>\n",
       "      <td>0.012433</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.025146</td>\n",
       "      <td>-0.042791</td>\n",
       "      <td>-0.020213</td>\n",
       "      <td>0.004129</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075918</td>\n",
       "      <td>0.012386</td>\n",
       "      <td>0.003751</td>\n",
       "      <td>0.009847</td>\n",
       "      <td>-0.001061</td>\n",
       "      <td>-0.003698</td>\n",
       "      <td>0.006597</td>\n",
       "      <td>-0.010696</td>\n",
       "      <td>-0.001886</td>\n",
       "      <td>0.029365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-04</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.000338</td>\n",
       "      <td>2021-03-04 00:00:00</td>\n",
       "      <td>-0.032831</td>\n",
       "      <td>-0.000420</td>\n",
       "      <td>-0.026692</td>\n",
       "      <td>-0.022037</td>\n",
       "      <td>-0.062958</td>\n",
       "      <td>-0.012583</td>\n",
       "      <td>0.012265</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039638</td>\n",
       "      <td>-0.042192</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>-0.011271</td>\n",
       "      <td>-0.019050</td>\n",
       "      <td>0.011018</td>\n",
       "      <td>0.019894</td>\n",
       "      <td>0.003833</td>\n",
       "      <td>-0.020687</td>\n",
       "      <td>-0.016134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-05</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.004654</td>\n",
       "      <td>2021-03-05 00:00:00</td>\n",
       "      <td>0.009179</td>\n",
       "      <td>-0.010915</td>\n",
       "      <td>-0.033954</td>\n",
       "      <td>-0.027541</td>\n",
       "      <td>-0.000290</td>\n",
       "      <td>-0.020885</td>\n",
       "      <td>0.006445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046093</td>\n",
       "      <td>-0.003294</td>\n",
       "      <td>0.012675</td>\n",
       "      <td>0.021432</td>\n",
       "      <td>-0.009275</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>0.020186</td>\n",
       "      <td>-0.009227</td>\n",
       "      <td>-0.002022</td>\n",
       "      <td>-0.035058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-08</th>\n",
       "      <td>1</td>\n",
       "      <td>0.013347</td>\n",
       "      <td>2021-03-08 00:00:00</td>\n",
       "      <td>0.036039</td>\n",
       "      <td>0.002547</td>\n",
       "      <td>-0.009125</td>\n",
       "      <td>0.039135</td>\n",
       "      <td>0.021437</td>\n",
       "      <td>0.002531</td>\n",
       "      <td>0.016137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019427</td>\n",
       "      <td>0.028501</td>\n",
       "      <td>-0.014752</td>\n",
       "      <td>-0.018750</td>\n",
       "      <td>0.045348</td>\n",
       "      <td>-0.000257</td>\n",
       "      <td>-0.021120</td>\n",
       "      <td>0.012042</td>\n",
       "      <td>0.038280</td>\n",
       "      <td>0.042778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-09</th>\n",
       "      <td>1</td>\n",
       "      <td>0.002852</td>\n",
       "      <td>2021-03-09 00:00:00</td>\n",
       "      <td>-0.044062</td>\n",
       "      <td>0.021169</td>\n",
       "      <td>0.005457</td>\n",
       "      <td>0.037661</td>\n",
       "      <td>-0.012479</td>\n",
       "      <td>0.028850</td>\n",
       "      <td>-0.002017</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020825</td>\n",
       "      <td>-0.004418</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>0.006941</td>\n",
       "      <td>0.015671</td>\n",
       "      <td>0.012851</td>\n",
       "      <td>-0.013012</td>\n",
       "      <td>-0.017421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-10</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.001171</td>\n",
       "      <td>2021-03-10 00:00:00</td>\n",
       "      <td>-0.009877</td>\n",
       "      <td>-0.007048</td>\n",
       "      <td>-0.001357</td>\n",
       "      <td>-0.003820</td>\n",
       "      <td>-0.030442</td>\n",
       "      <td>-0.027340</td>\n",
       "      <td>-0.004799</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008828</td>\n",
       "      <td>0.007261</td>\n",
       "      <td>0.003135</td>\n",
       "      <td>0.004521</td>\n",
       "      <td>0.015917</td>\n",
       "      <td>0.005872</td>\n",
       "      <td>-0.004025</td>\n",
       "      <td>0.012845</td>\n",
       "      <td>0.001978</td>\n",
       "      <td>-0.016300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1260 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            target     index              level_0    AAL-LN    ABF-LN  \\\n",
       "level_0                                                                 \n",
       "2016-03-14       1  0.004692  2016-03-14 00:00:00  0.059930  0.004770   \n",
       "2016-03-15       0 -0.005928  2016-03-15 00:00:00 -0.108051  0.000000   \n",
       "2016-03-16       1  0.006325  2016-03-16 00:00:00  0.010770  0.005045   \n",
       "2016-03-17       0 -0.006285  2016-03-17 00:00:00  0.097828 -0.002657   \n",
       "2016-03-18       0 -0.002530  2016-03-18 00:00:00  0.026807  0.012433   \n",
       "...            ...       ...                  ...       ...       ...   \n",
       "2021-03-04       0 -0.000338  2021-03-04 00:00:00 -0.032831 -0.000420   \n",
       "2021-03-05       0 -0.004654  2021-03-05 00:00:00  0.009179 -0.010915   \n",
       "2021-03-08       1  0.013347  2021-03-08 00:00:00  0.036039  0.002547   \n",
       "2021-03-09       1  0.002852  2021-03-09 00:00:00 -0.044062  0.021169   \n",
       "2021-03-10       0 -0.001171  2021-03-10 00:00:00 -0.009877 -0.007048   \n",
       "\n",
       "              ADM-LN    AHT-LN   ANTO-LN   AUTO-LN    AV.-LN  ...   STAN-LN  \\\n",
       "level_0                                                       ...             \n",
       "2016-03-14 -0.020366  0.038217  0.025763 -0.001576 -0.025636  ...  0.033668   \n",
       "2016-03-15  0.006397  0.001227 -0.044651 -0.001842 -0.013466  ... -0.040430   \n",
       "2016-03-16  0.006356  0.023284 -0.033301  0.011337  0.014070  ... -0.016595   \n",
       "2016-03-17  0.007895  0.023952  0.082796 -0.019812  0.003106  ...  0.006027   \n",
       "2016-03-18  0.001044  0.025146 -0.042791 -0.020213  0.004129  ...  0.075918   \n",
       "...              ...       ...       ...       ...       ...  ...       ...   \n",
       "2021-03-04 -0.026692 -0.022037 -0.062958 -0.012583  0.012265  ... -0.039638   \n",
       "2021-03-05 -0.033954 -0.027541 -0.000290 -0.020885  0.006445  ...  0.046093   \n",
       "2021-03-08 -0.009125  0.039135  0.021437  0.002531  0.016137  ...  0.019427   \n",
       "2021-03-09  0.005457  0.037661 -0.012479  0.028850 -0.002017  ... -0.020825   \n",
       "2021-03-10 -0.001357 -0.003820 -0.030442 -0.027340 -0.004799  ... -0.008828   \n",
       "\n",
       "              STJ-LN    SVT-LN   TSCO-LN    TW.-LN   ULVR-LN    UU.-LN  \\\n",
       "level_0                                                                  \n",
       "2016-03-14  0.010626  0.000485  0.004943  0.029826  0.004683  0.007804   \n",
       "2016-03-15 -0.003874  0.006783 -0.015015 -0.008743  0.010609 -0.004978   \n",
       "2016-03-16  0.038333  0.011550  0.002103  0.034179 -0.006044  0.002223   \n",
       "2016-03-17 -0.006421  0.014748  0.012064  0.004797 -0.004641  0.008874   \n",
       "2016-03-18  0.012386  0.003751  0.009847 -0.001061 -0.003698  0.006597   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2021-03-04 -0.042192  0.018911 -0.011271 -0.019050  0.011018  0.019894   \n",
       "2021-03-05 -0.003294  0.012675  0.021432 -0.009275  0.009600  0.020186   \n",
       "2021-03-08  0.028501 -0.014752 -0.018750  0.045348 -0.000257 -0.021120   \n",
       "2021-03-09 -0.004418  0.013158  0.006369  0.002239  0.006941  0.015671   \n",
       "2021-03-10  0.007261  0.003135  0.004521  0.015917  0.005872 -0.004025   \n",
       "\n",
       "              VOD-LN    WPP-LN    WTB-LN  \n",
       "level_0                                   \n",
       "2016-03-14  0.010352  0.006390  0.035554  \n",
       "2016-03-15  0.001366  0.011429 -0.023398  \n",
       "2016-03-16  0.001592  0.002511 -0.008854  \n",
       "2016-03-17 -0.002497 -0.003757  0.002102  \n",
       "2016-03-18 -0.010696 -0.001886  0.029365  \n",
       "...              ...       ...       ...  \n",
       "2021-03-04  0.003833 -0.020687 -0.016134  \n",
       "2021-03-05 -0.009227 -0.002022 -0.035058  \n",
       "2021-03-08  0.012042  0.038280  0.042778  \n",
       "2021-03-09  0.012851 -0.013012 -0.017421  \n",
       "2021-03-10  0.012845  0.001978 -0.016300  \n",
       "\n",
       "[1260 rows x 96 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftse_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '2016-03-14 00:00:00'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-74e7a4a19e89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#basket_returns = ftse_prediction#normalise_basket(df, 'returns')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \"\"\"\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         X = self._validate_data(X, dtype=[np.float64, np.float32],\n\u001b[0;32m--> 398\u001b[0;31m                                 ensure_2d=True, copy=self.copy)\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;31m# Handle n_components==None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    418\u001b[0m                     \u001b[0;34mf\"requires y to be passed, but the target y is None.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m                 )\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    596\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1778\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '2016-03-14 00:00:00'"
     ]
    }
   ],
   "source": [
    "# Principal Component Analysis\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = ftse_prediction[list(filter(lambda ticker: ticker not in  ['index', 'target'], ftse_prediction.columns))]\n",
    "\n",
    "#basket_returns = ftse_prediction#normalise_basket(df, 'returns')\n",
    "pca = PCA()\n",
    "pca.fit(df)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "y = np.round(pca.explained_variance_ratio_* 100, decimals =2)\n",
    "plt.bar(x=range(0, pca.components_[0].size), height=y)\n",
    "plt.xticks(range(0, pca.components_[0].size), rotation=90)\n",
    "plt.show()\n",
    "\n",
    "# Visualise first component\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.bar(x=range(0, pca.components_[0].size), height=pca.components_[0])\n",
    "plt.xticks(range(0, pca.components_[0].size), df.columns, rotation=90)\n",
    "plt.show()\n",
    "\n",
    "ftse_pca_score = pca.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "# Train/Test subsetting\n",
    "#######################\n",
    "from datetime import datetime\n",
    "\n",
    "train_start = pd.to_datetime('16/05/2019')\n",
    "train_end = pd.to_datetime('31/01/2021')\n",
    "\n",
    "train_mask = lambda s: (s.index > train_start) & (s.index <= train_end)\n",
    "test_mask = lambda s: (s.index > train_end) & (s.index <= datetime.now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9068b7278de5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "X_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.0\n",
      "Model score: -0.03164587699060917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.1,\n",
       " 'copy_X': True,\n",
       " 'fit_intercept': True,\n",
       " 'max_iter': 1000,\n",
       " 'normalize': False,\n",
       " 'positive': False,\n",
       " 'precompute': False,\n",
       " 'random_state': None,\n",
       " 'selection': 'cyclic',\n",
       " 'tol': 0.0001,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################\n",
    "# Lasso regression\n",
    "#  y: ftse price \n",
    "#  X: basket of stocks\n",
    "######################\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "X_train=ftse_prediction[train_mask(ftse_prediction)][test_cols]\n",
    "y_train=ftse_prediction[train_mask(ftse_prediction)]['index']\n",
    "\n",
    "X_test = ftse_prediction[test_mask(ftse_prediction)][test_cols]\n",
    "y_test = ftse_prediction[test_mask(ftse_prediction)]['index']\n",
    "clf = Lasso(alpha=0.1)\n",
    "clf.fit(X=X_train, y=y_train)\n",
    "print(f'Train Score: {clf.score(X=X_train, y=y_train)}')\n",
    "print(f'Model score: {clf.score(X=X_test, y=y_test)}')\n",
    "clf.get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               SARIMAX Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:                  index   No. Observations:                 1253\n",
      "Model:                 ARIMA(5, 1, 0)   Log Likelihood               -1007.412\n",
      "Date:                Sat, 13 Mar 2021   AIC                           2026.824\n",
      "Time:                        15:57:31   BIC                           2057.619\n",
      "Sample:                             0   HQIC                          2038.400\n",
      "                               - 1253                                         \n",
      "Covariance Type:                  opg                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "ar.L1         -0.8155      0.028    -28.617      0.000      -0.871      -0.760\n",
      "ar.L2         -0.6630      0.036    -18.603      0.000      -0.733      -0.593\n",
      "ar.L3         -0.5292      0.038    -14.078      0.000      -0.603      -0.456\n",
      "ar.L4         -0.3544      0.036     -9.851      0.000      -0.425      -0.284\n",
      "ar.L5         -0.1658      0.029     -5.773      0.000      -0.222      -0.110\n",
      "sigma2         0.2925      0.023     12.552      0.000       0.247       0.338\n",
      "===================================================================================\n",
      "Ljung-Box (Q):                      103.14   Jarque-Bera (JB):               116.77\n",
      "Prob(Q):                              0.00   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               1.04   Skew:                            -0.06\n",
      "Prob(H) (two-sided):                  0.66   Kurtosis:                         1.51\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rory/.local/lib/python3.6/site-packages/statsmodels/tsa/base/tsa_model.py:218: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "/home/rory/.local/lib/python3.6/site-packages/statsmodels/tsa/base/tsa_model.py:218: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "/home/rory/.local/lib/python3.6/site-packages/statsmodels/tsa/base/tsa_model.py:218: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 0\n",
      "count  1253.000000\n",
      "mean      0.001207\n",
      "std       0.540906\n",
      "min      -1.000000\n",
      "25%      -0.506819\n",
      "50%       0.133733\n",
      "75%       0.497167\n",
      "max       1.000000\n"
     ]
    }
   ],
   "source": [
    "# fit an ARIMA model and plot residual errors\n",
    "from pandas import datetime\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from matplotlib import pyplot\n",
    "# load dataset\n",
    "\n",
    "series = ftse_prediction['index'].astype('float')\n",
    "\n",
    "# fit model\n",
    "model = ARIMA(series, order=(5,1,0))\n",
    "model_fit = model.fit()\n",
    "# summary of fit model\n",
    "print(model_fit.summary())\n",
    "# line plot of residuals\n",
    "residuals = DataFrame(model_fit.resid)\n",
    "residuals.plot()\n",
    "pyplot.show()\n",
    "# density plot of residuals\n",
    "residuals.plot(kind='kde')\n",
    "pyplot.show()\n",
    "# summary stats of residuals\n",
    "print(residuals.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.05075381847664118"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###########################################\n",
    "# Lasso regression on classification target\n",
    "# of increase or decrease daily returns\n",
    "###########################################\n",
    "\n",
    "X_train=ftse_prediction[train_mask(ftse_prediction)][list(filter(lambda it: it not in ['index','target'], ftse_prediction.columns))]\n",
    "y_train=ftse_prediction[train_mask(ftse_prediction)]['target'].astype('int')\n",
    "\n",
    "X_test = ftse_prediction[test_mask(ftse_prediction)][list(filter(lambda it: it not in ['index','target'], ftse_prediction.columns))]\n",
    "y_test = ftse_prediction[test_mask(ftse_prediction)]['target'].astype('int')\n",
    "clf = Lasso(alpha=0.001)\n",
    "clf.fit(X=X_train, y=y_train)\n",
    "clf.score(X=X_test, y=y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.41525002, 0.64512416, 0.56298973, 0.53380882, 0.496402  ,\n",
       "       0.50808069, 0.47106454, 0.54674915, 0.52676112, 0.47659536,\n",
       "       0.49241966, 0.53628927, 0.46546311, 0.51316665, 0.57157871,\n",
       "       0.54199161, 0.50905784, 0.50185658, 0.53502689, 0.49030831,\n",
       "       0.50941265, 0.55950494, 0.46498994, 0.48509406, 0.50257621,\n",
       "       0.55472171])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import  NearestCentroid\n",
    "train_mask(ftse_prediction)\n",
    "\n",
    "features_train = ftse_prediction[train_mask(ftse_prediction)][test_cols]\n",
    "features_test = ftse_prediction[test_mask(ftse_prediction)][test_cols]\n",
    "target_train = ftse_prediction[train_mask(ftse_prediction)][['target']].astype('int')\n",
    "target_test = ftse_prediction[test_mask(ftse_prediction)]['target'].astype('int')\n",
    "\n",
    "pca = PCA()\n",
    "target = ftse_prediction['target']\n",
    "\n",
    "clf = NearestCentroid()\n",
    "\n",
    "#pca.fit(features_train)\n",
    "#features_train = pca.transform(features_train)\n",
    "#features_test = pca.transform(features_test)\n",
    "clf.fit(X=features_train, y=target_train)\n",
    "\n",
    "clf.score(y=target_test, X=features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.75\n",
      "Accuracy score (training): 1.000\n",
      "Accuracy score (validation): 0.462\n",
      "Learning rate:  1\n",
      "Accuracy score (training): 1.000\n",
      "Accuracy score (validation): 0.615\n",
      "Learning rate:  1.1\n",
      "Accuracy score (training): 1.000\n",
      "Accuracy score (validation): 0.500\n",
      "Learning rate:  1.2\n",
      "Accuracy score (training): 1.000\n",
      "Accuracy score (validation): 0.500\n",
      "Learning rate:  1.3\n",
      "Accuracy score (training): 1.000\n",
      "Accuracy score (validation): 0.654\n",
      "Learning rate:  1.4\n",
      "Accuracy score (training): 1.000\n",
      "Accuracy score (validation): 0.654\n",
      "Accuracy score (training): 1.000\n",
      "Accuracy score (validation): 0.462\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "lr_list = [0.75, 1, 1.1, 1.2, 1.3, 1.4]\n",
    "\n",
    "for learning_rate in lr_list:\n",
    "    gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=learning_rate, max_features=30, max_depth=10, random_state=0)\n",
    "    gb_clf.fit(X_train, y_train)\n",
    "    print(\"Learning rate: \", learning_rate)\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(gb_clf.score(X_train, y_train)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(gb_clf.score(X_test, y_test)))\n",
    "    \n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.75, max_features=30, max_depth=10, random_state=0)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "print(\"Accuracy score (training): {0:.3f}\".format(gb_clf.score(X_train, y_train)))\n",
    "print(\"Accuracy score (validation): {0:.3f}\".format(gb_clf.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-f10a0a9799fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgb_clf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfeat_test_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'features_test' is not defined"
     ]
    }
   ],
   "source": [
    "clf = gb_clf\n",
    "\n",
    "clf.predict(features_test)\n",
    "pca.fit(features_train)\n",
    "feat_test_df = pd.DataFrame(pca.transform(features_test))\n",
    "prediction = clf.predict(features_test)\n",
    "\n",
    "\n",
    "def printtable():\n",
    "    print(f'|Actual| Pred| PC1| PC2')\n",
    "    print(f'--------------')\n",
    "\n",
    "    for pred, act, pc1, pc2, targ in zip(clf.predict(features_test), \n",
    "                                         target_test, \n",
    "                                         feat_test_df[0], \n",
    "                                         feat_test_df[1], \n",
    "                                         ftse_prediction['index']):\n",
    "        print('     {}|    {}|   {:0.2f}|   {:0.2f}|  {:0.2f}'.format(act, pred, pc1, pc2, targ))\n",
    "        print('--------------')\n",
    "\n",
    "\n",
    "cols = ['Actual', 'Predicted', 'PC1', 'PC2']\n",
    "vals = [target_test, clf.predict(features_test)]\n",
    "\n",
    "to_plot = pd.DataFrame()\n",
    "\n",
    "to_plot['PC1'] = feat_test_df[0]\n",
    "to_plot['PC2'] = feat_test_df[1]\n",
    "to_plot['PC3'] = feat_test_df[2]\n",
    "to_plot['PC4'] = feat_test_df[3]\n",
    "to_plot['Actual'] = target_test.values\n",
    "to_plot['Predicted'] = clf.predict(features_test)\n",
    "fig, ax = plt.subplots()\n",
    "colors = {0: 'red', 1: 'green'}\n",
    "ax.scatter(to_plot['PC2'], to_plot['PC3'], c=to_plot['Actual'].map(colors))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax1 = to_plot.plot.scatter(x='PC1', y='PC2', color=to_plot['Predicted'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "level_0\n",
       "2019-05-17    0.002613\n",
       "2019-05-20    0.000613\n",
       "2019-05-21   -0.013174\n",
       "2019-05-22    0.006830\n",
       "2019-05-23   -0.002467\n",
       "                ...   \n",
       "2021-01-25   -0.012941\n",
       "2021-01-26   -0.005520\n",
       "2021-01-27   -0.018907\n",
       "2021-01-28    0.009547\n",
       "2021-01-29    0.008406\n",
       "Name: index, Length: 432, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list(filter( lambda model: model.ready(), models))\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-5aee45d4ebf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0msh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGradientBoostingRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameter_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0msh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    713\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 715\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params={'n_estimators': 10000, 'learning_rate': 0.01, 'max_features': 30, 'max_depth': 4, 'random_state': 0}\n",
    "\n",
    "parameter_space = {\n",
    "    \"alpha\": [0.1, 0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\n",
    "    'learning_rate': [0.1,0.2,0.3,0.4,0.5],\n",
    "    'max_depth': [2,4,6,8,10],\n",
    "    'max_features': [10,20,30,40,50,60],\n",
    "    'min_samples_leaf': [1,2,3],\n",
    "    'min_samples_split': [2,5,10],\n",
    "    'n_estimators': [500,1000,2000,3000,4000,5000],\n",
    "    'random_state': [0,1,2,3,4,5,6],\n",
    "    'warm_start': [False,True]\n",
    "}\n",
    "\n",
    "#base_estimator = GradientBoostingRegressor()\n",
    "#gb_reg.fit(X_train, y_train)\n",
    "\n",
    "sh = GridSearchCV(GradientBoostingRegressor(), parameter_space, n_jobs=8, pre_dispatch=16)\n",
    "sh.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.9,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'criterion': 'friedman_mse',\n",
       " 'init': None,\n",
       " 'learning_rate': 0.1,\n",
       " 'loss': 'ls',\n",
       " 'max_depth': 4,\n",
       " 'max_features': 30,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 1000,\n",
       " 'n_iter_no_change': None,\n",
       " 'presort': 'deprecated',\n",
       " 'random_state': 0,\n",
       " 'subsample': 1.0,\n",
       " 'tol': 0.0001,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_reg.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6428571428571429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/rory/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train=ftse_prediction[train_mask(ftse_prediction)][test_cols]\n",
    "y_train=ftse_prediction[train_mask(ftse_prediction)]['target'].astype('int')\n",
    "X_test = ftse_prediction[test_mask(ftse_prediction)][test_cols]\n",
    "y_test = ftse_prediction[test_mask(ftse_prediction)]['target'].astype('int')\n",
    "\n",
    "clf = SVC(kernel='sigmoid')\n",
    "\n",
    "clf.fit(X=features_train,y=target_train)\n",
    "y_pred = clf.predict(features_test)\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C-Support Vector Classification.\n",
      "\n",
      "    The implementation is based on libsvm. The fit time scales at least\n",
      "    quadratically with the number of samples and may be impractical\n",
      "    beyond tens of thousands of samples. For large datasets\n",
      "    consider using :class:`sklearn.svm.LinearSVC` or\n",
      "    :class:`sklearn.linear_model.SGDClassifier` instead, possibly after a\n",
      "    :class:`sklearn.kernel_approximation.Nystroem` transformer.\n",
      "\n",
      "    The multiclass support is handled according to a one-vs-one scheme.\n",
      "\n",
      "    For details on the precise mathematical formulation of the provided\n",
      "    kernel functions and how `gamma`, `coef0` and `degree` affect each\n",
      "    other, see the corresponding section in the narrative documentation:\n",
      "    :ref:`svm_kernels`.\n",
      "\n",
      "    Read more in the :ref:`User Guide <svm_classification>`.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    C : float, default=1.0\n",
      "        Regularization parameter. The strength of the regularization is\n",
      "        inversely proportional to C. Must be strictly positive. The penalty\n",
      "        is a squared l2 penalty.\n",
      "\n",
      "    kernel : {'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'}, default='rbf'\n",
      "        Specifies the kernel type to be used in the algorithm.\n",
      "        It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n",
      "        a callable.\n",
      "        If none is given, 'rbf' will be used. If a callable is given it is\n",
      "        used to pre-compute the kernel matrix from data matrices; that matrix\n",
      "        should be an array of shape ``(n_samples, n_samples)``.\n",
      "\n",
      "    degree : int, default=3\n",
      "        Degree of the polynomial kernel function ('poly').\n",
      "        Ignored by all other kernels.\n",
      "\n",
      "    gamma : {'scale', 'auto'} or float, default='scale'\n",
      "        Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
      "\n",
      "        - if ``gamma='scale'`` (default) is passed then it uses\n",
      "          1 / (n_features * X.var()) as value of gamma,\n",
      "        - if 'auto', uses 1 / n_features.\n",
      "\n",
      "        .. versionchanged:: 0.22\n",
      "           The default value of ``gamma`` changed from 'auto' to 'scale'.\n",
      "\n",
      "    coef0 : float, default=0.0\n",
      "        Independent term in kernel function.\n",
      "        It is only significant in 'poly' and 'sigmoid'.\n",
      "\n",
      "    shrinking : bool, default=True\n",
      "        Whether to use the shrinking heuristic.\n",
      "        See the :ref:`User Guide <shrinking_svm>`.\n",
      "\n",
      "    probability : bool, default=False\n",
      "        Whether to enable probability estimates. This must be enabled prior\n",
      "        to calling `fit`, will slow down that method as it internally uses\n",
      "        5-fold cross-validation, and `predict_proba` may be inconsistent with\n",
      "        `predict`. Read more in the :ref:`User Guide <scores_probabilities>`.\n",
      "\n",
      "    tol : float, default=1e-3\n",
      "        Tolerance for stopping criterion.\n",
      "\n",
      "    cache_size : float, default=200\n",
      "        Specify the size of the kernel cache (in MB).\n",
      "\n",
      "    class_weight : dict or 'balanced', default=None\n",
      "        Set the parameter C of class i to class_weight[i]*C for\n",
      "        SVC. If not given, all classes are supposed to have\n",
      "        weight one.\n",
      "        The \"balanced\" mode uses the values of y to automatically adjust\n",
      "        weights inversely proportional to class frequencies in the input data\n",
      "        as ``n_samples / (n_classes * np.bincount(y))``\n",
      "\n",
      "    verbose : bool, default=False\n",
      "        Enable verbose output. Note that this setting takes advantage of a\n",
      "        per-process runtime setting in libsvm that, if enabled, may not work\n",
      "        properly in a multithreaded context.\n",
      "\n",
      "    max_iter : int, default=-1\n",
      "        Hard limit on iterations within solver, or -1 for no limit.\n",
      "\n",
      "    decision_function_shape : {'ovo', 'ovr'}, default='ovr'\n",
      "        Whether to return a one-vs-rest ('ovr') decision function of shape\n",
      "        (n_samples, n_classes) as all other classifiers, or the original\n",
      "        one-vs-one ('ovo') decision function of libsvm which has shape\n",
      "        (n_samples, n_classes * (n_classes - 1) / 2). However, one-vs-one\n",
      "        ('ovo') is always used as multi-class strategy. The parameter is\n",
      "        ignored for binary classification.\n",
      "\n",
      "        .. versionchanged:: 0.19\n",
      "            decision_function_shape is 'ovr' by default.\n",
      "\n",
      "        .. versionadded:: 0.17\n",
      "           *decision_function_shape='ovr'* is recommended.\n",
      "\n",
      "        .. versionchanged:: 0.17\n",
      "           Deprecated *decision_function_shape='ovo' and None*.\n",
      "\n",
      "    break_ties : bool, default=False\n",
      "        If true, ``decision_function_shape='ovr'``, and number of classes > 2,\n",
      "        :term:`predict` will break ties according to the confidence values of\n",
      "        :term:`decision_function`; otherwise the first class among the tied\n",
      "        classes is returned. Please note that breaking ties comes at a\n",
      "        relatively high computational cost compared to a simple predict.\n",
      "\n",
      "        .. versionadded:: 0.22\n",
      "\n",
      "    random_state : int or RandomState instance, default=None\n",
      "        Controls the pseudo random number generation for shuffling the data for\n",
      "        probability estimates. Ignored when `probability` is False.\n",
      "        Pass an int for reproducible output across multiple function calls.\n",
      "        See :term:`Glossary <random_state>`.\n",
      "\n",
      "    Attributes\n",
      "    ----------\n",
      "    support_ : ndarray of shape (n_SV,)\n",
      "        Indices of support vectors.\n",
      "\n",
      "    support_vectors_ : ndarray of shape (n_SV, n_features)\n",
      "        Support vectors.\n",
      "\n",
      "    n_support_ : ndarray of shape (n_class,), dtype=int32\n",
      "        Number of support vectors for each class.\n",
      "\n",
      "    dual_coef_ : ndarray of shape (n_class-1, n_SV)\n",
      "        Dual coefficients of the support vector in the decision\n",
      "        function (see :ref:`sgd_mathematical_formulation`), multiplied by\n",
      "        their targets.\n",
      "        For multiclass, coefficient for all 1-vs-1 classifiers.\n",
      "        The layout of the coefficients in the multiclass case is somewhat\n",
      "        non-trivial. See the :ref:`multi-class section of the User Guide\n",
      "        <svm_multi_class>` for details.\n",
      "\n",
      "    coef_ : ndarray of shape (n_class * (n_class-1) / 2, n_features)\n",
      "        Weights assigned to the features (coefficients in the primal\n",
      "        problem). This is only available in the case of a linear kernel.\n",
      "\n",
      "        `coef_` is a readonly property derived from `dual_coef_` and\n",
      "        `support_vectors_`.\n",
      "\n",
      "    intercept_ : ndarray of shape (n_class * (n_class-1) / 2,)\n",
      "        Constants in decision function.\n",
      "\n",
      "    fit_status_ : int\n",
      "        0 if correctly fitted, 1 otherwise (will raise warning)\n",
      "\n",
      "    classes_ : ndarray of shape (n_classes,)\n",
      "        The classes labels.\n",
      "\n",
      "    probA_ : ndarray of shape (n_class * (n_class-1) / 2)\n",
      "    probB_ : ndarray of shape (n_class * (n_class-1) / 2)\n",
      "        If `probability=True`, it corresponds to the parameters learned in\n",
      "        Platt scaling to produce probability estimates from decision values.\n",
      "        If `probability=False`, it's an empty array. Platt scaling uses the\n",
      "        logistic function\n",
      "        ``1 / (1 + exp(decision_value * probA_ + probB_))``\n",
      "        where ``probA_`` and ``probB_`` are learned from the dataset [2]_. For\n",
      "        more information on the multiclass case and training procedure see\n",
      "        section 8 of [1]_.\n",
      "\n",
      "    class_weight_ : ndarray of shape (n_class,)\n",
      "        Multipliers of parameter C for each class.\n",
      "        Computed based on the ``class_weight`` parameter.\n",
      "\n",
      "    shape_fit_ : tuple of int of shape (n_dimensions_of_X,)\n",
      "        Array dimensions of training vector ``X``.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> import numpy as np\n",
      "    >>> from sklearn.pipeline import make_pipeline\n",
      "    >>> from sklearn.preprocessing import StandardScaler\n",
      "    >>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
      "    >>> y = np.array([1, 1, 2, 2])\n",
      "    >>> from sklearn.svm import SVC\n",
      "    >>> clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
      "    >>> clf.fit(X, y)\n",
      "    Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                    ('svc', SVC(gamma='auto'))])\n",
      "\n",
      "    >>> print(clf.predict([[-0.8, -1]]))\n",
      "    [1]\n",
      "\n",
      "    See also\n",
      "    --------\n",
      "    SVR\n",
      "        Support Vector Machine for Regression implemented using libsvm.\n",
      "\n",
      "    LinearSVC\n",
      "        Scalable Linear Support Vector Machine for classification\n",
      "        implemented using liblinear. Check the See also section of\n",
      "        LinearSVC for more comparison element.\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "    .. [1] `LIBSVM: A Library for Support Vector Machines\n",
      "        <http://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf>`_\n",
      "\n",
      "    .. [2] `Platt, John (1999). \"Probabilistic outputs for support vector\n",
      "        machines and comparison to regularizedlikelihood methods.\"\n",
      "        <http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.1639>`_\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(SVC.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAL-LN</th>\n",
       "      <th>ABF-LN</th>\n",
       "      <th>ADM-LN</th>\n",
       "      <th>AHT-LN</th>\n",
       "      <th>ANTO-LN</th>\n",
       "      <th>AUTO-LN</th>\n",
       "      <th>AV.-LN</th>\n",
       "      <th>AVV-LN</th>\n",
       "      <th>AZN-LN</th>\n",
       "      <th>BA.-LN</th>\n",
       "      <th>...</th>\n",
       "      <th>STJ-LN</th>\n",
       "      <th>SVT-LN</th>\n",
       "      <th>TSCO-LN</th>\n",
       "      <th>TW.-LN</th>\n",
       "      <th>ULVR-LN</th>\n",
       "      <th>UU.-LN</th>\n",
       "      <th>VOD-LN</th>\n",
       "      <th>WPP-LN</th>\n",
       "      <th>WTB-LN</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-03-02</th>\n",
       "      <td>-0.143746</td>\n",
       "      <td>-0.684988</td>\n",
       "      <td>2.359227</td>\n",
       "      <td>1.663758</td>\n",
       "      <td>-0.763949</td>\n",
       "      <td>-0.891150</td>\n",
       "      <td>2.276241</td>\n",
       "      <td>2.914591</td>\n",
       "      <td>6.692308</td>\n",
       "      <td>-0.749494</td>\n",
       "      <td>...</td>\n",
       "      <td>0.525676</td>\n",
       "      <td>0.990152</td>\n",
       "      <td>-0.902840</td>\n",
       "      <td>-0.945784</td>\n",
       "      <td>1.464124</td>\n",
       "      <td>0.521724</td>\n",
       "      <td>-0.958054</td>\n",
       "      <td>0.068882</td>\n",
       "      <td>15.250000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-03</th>\n",
       "      <td>0.009298</td>\n",
       "      <td>0.006760</td>\n",
       "      <td>-0.016563</td>\n",
       "      <td>0.028975</td>\n",
       "      <td>-0.005666</td>\n",
       "      <td>0.011311</td>\n",
       "      <td>0.027346</td>\n",
       "      <td>-0.014773</td>\n",
       "      <td>-0.012500</td>\n",
       "      <td>0.007265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030894</td>\n",
       "      <td>-0.024741</td>\n",
       "      <td>-0.002698</td>\n",
       "      <td>0.059976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.020394</td>\n",
       "      <td>0.008698</td>\n",
       "      <td>0.031087</td>\n",
       "      <td>0.055490</td>\n",
       "      <td>0.009392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-04</th>\n",
       "      <td>-0.032831</td>\n",
       "      <td>-0.000420</td>\n",
       "      <td>-0.026692</td>\n",
       "      <td>-0.022037</td>\n",
       "      <td>-0.062958</td>\n",
       "      <td>-0.012583</td>\n",
       "      <td>0.012265</td>\n",
       "      <td>-0.014418</td>\n",
       "      <td>0.009273</td>\n",
       "      <td>-0.003406</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042192</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>-0.011271</td>\n",
       "      <td>-0.019050</td>\n",
       "      <td>0.011018</td>\n",
       "      <td>0.019894</td>\n",
       "      <td>0.003833</td>\n",
       "      <td>-0.020687</td>\n",
       "      <td>-0.016134</td>\n",
       "      <td>-0.000338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-05</th>\n",
       "      <td>0.009179</td>\n",
       "      <td>-0.010915</td>\n",
       "      <td>-0.033954</td>\n",
       "      <td>-0.027541</td>\n",
       "      <td>-0.000290</td>\n",
       "      <td>-0.020885</td>\n",
       "      <td>0.006445</td>\n",
       "      <td>-0.022528</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>-0.027945</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003294</td>\n",
       "      <td>0.012675</td>\n",
       "      <td>0.021432</td>\n",
       "      <td>-0.009275</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>0.020186</td>\n",
       "      <td>-0.009227</td>\n",
       "      <td>-0.002022</td>\n",
       "      <td>-0.035058</td>\n",
       "      <td>-0.004654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-08</th>\n",
       "      <td>0.036039</td>\n",
       "      <td>0.002547</td>\n",
       "      <td>-0.009125</td>\n",
       "      <td>0.039135</td>\n",
       "      <td>0.021437</td>\n",
       "      <td>0.002531</td>\n",
       "      <td>0.016137</td>\n",
       "      <td>0.016761</td>\n",
       "      <td>0.021435</td>\n",
       "      <td>0.026680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028501</td>\n",
       "      <td>-0.014752</td>\n",
       "      <td>-0.018750</td>\n",
       "      <td>0.045348</td>\n",
       "      <td>-0.000257</td>\n",
       "      <td>-0.021120</td>\n",
       "      <td>0.012042</td>\n",
       "      <td>0.038280</td>\n",
       "      <td>0.042778</td>\n",
       "      <td>0.013347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-09</th>\n",
       "      <td>-0.044062</td>\n",
       "      <td>0.021169</td>\n",
       "      <td>0.005457</td>\n",
       "      <td>0.037661</td>\n",
       "      <td>-0.012479</td>\n",
       "      <td>0.028850</td>\n",
       "      <td>-0.002017</td>\n",
       "      <td>0.016780</td>\n",
       "      <td>0.017987</td>\n",
       "      <td>0.005036</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004418</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>0.006941</td>\n",
       "      <td>0.015671</td>\n",
       "      <td>0.012851</td>\n",
       "      <td>-0.013012</td>\n",
       "      <td>-0.017421</td>\n",
       "      <td>0.002852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              AAL-LN    ABF-LN    ADM-LN    AHT-LN   ANTO-LN   AUTO-LN  \\\n",
       "2021-03-02 -0.143746 -0.684988  2.359227  1.663758 -0.763949 -0.891150   \n",
       "2021-03-03  0.009298  0.006760 -0.016563  0.028975 -0.005666  0.011311   \n",
       "2021-03-04 -0.032831 -0.000420 -0.026692 -0.022037 -0.062958 -0.012583   \n",
       "2021-03-05  0.009179 -0.010915 -0.033954 -0.027541 -0.000290 -0.020885   \n",
       "2021-03-08  0.036039  0.002547 -0.009125  0.039135  0.021437  0.002531   \n",
       "2021-03-09 -0.044062  0.021169  0.005457  0.037661 -0.012479  0.028850   \n",
       "\n",
       "              AV.-LN    AVV-LN    AZN-LN    BA.-LN  ...    STJ-LN    SVT-LN  \\\n",
       "2021-03-02  2.276241  2.914591  6.692308 -0.749494  ...  0.525676  0.990152   \n",
       "2021-03-03  0.027346 -0.014773 -0.012500  0.007265  ...  0.030894 -0.024741   \n",
       "2021-03-04  0.012265 -0.014418  0.009273 -0.003406  ... -0.042192  0.018911   \n",
       "2021-03-05  0.006445 -0.022528  0.000146 -0.027945  ... -0.003294  0.012675   \n",
       "2021-03-08  0.016137  0.016761  0.021435  0.026680  ...  0.028501 -0.014752   \n",
       "2021-03-09 -0.002017  0.016780  0.017987  0.005036  ... -0.004418  0.013158   \n",
       "\n",
       "             TSCO-LN    TW.-LN   ULVR-LN    UU.-LN    VOD-LN    WPP-LN  \\\n",
       "2021-03-02 -0.902840 -0.945784  1.464124  0.521724 -0.958054  0.068882   \n",
       "2021-03-03 -0.002698  0.059976  0.000000 -0.020394  0.008698  0.031087   \n",
       "2021-03-04 -0.011271 -0.019050  0.011018  0.019894  0.003833 -0.020687   \n",
       "2021-03-05  0.021432 -0.009275  0.009600  0.020186 -0.009227 -0.002022   \n",
       "2021-03-08 -0.018750  0.045348 -0.000257 -0.021120  0.012042  0.038280   \n",
       "2021-03-09  0.006369  0.002239  0.006941  0.015671  0.012851 -0.013012   \n",
       "\n",
       "               WTB-LN    target  \n",
       "2021-03-02  15.250000       NaN  \n",
       "2021-03-03   0.055490  0.009392  \n",
       "2021-03-04  -0.016134 -0.000338  \n",
       "2021-03-05  -0.035058 -0.004654  \n",
       "2021-03-08   0.042778  0.013347  \n",
       "2021-03-09  -0.017421  0.002852  \n",
       "\n",
       "[6 rows x 94 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_week = ftse_basket.get_historical_prices(range='1w')\n",
    "\n",
    "last_week = process_basket_data(last_week)\n",
    "last_week_data = normalise_basket(last_week, 'returns')\n",
    "last_week_data\n",
    "\n",
    "features = last_week_data[list(filter(lambda col: col not in ['filter', 'target'], last_week_data.columns))]\n",
    "\n",
    "features = features[features.replace([np.inf, -np.inf], np.nan).notnull()]\n",
    "features = features[filter(lambda item: item not in ['target', 'index'] ,ftse_prediction.columns)]\n",
    "\n",
    "last_week_target = ftse100.get_historical_prices(range='1w').close.astype('float').pct_change()\n",
    "features['target'] = last_week_target\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(gb_clf.predict(features[test_cols].dropna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2021-03-02         NaN\n",
       "2021-03-03    0.009392\n",
       "2021-03-04   -0.000338\n",
       "2021-03-05   -0.004654\n",
       "2021-03-08    0.013347\n",
       "2021-03-09    0.002852\n",
       "Name: close, dtype: float64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_week_target"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
